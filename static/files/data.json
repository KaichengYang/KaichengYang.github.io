{
	"news_list": [
        {
            "date": "Nov 16, 2020",
            "msg": "New preprint <b>Model-free hidden geometry of complex networks</b> available"
        },
        {
            "date": "Oct 27, 2020",
            "msg": "New preprint <b>The Manufacture of Political Echo Chambers by Follow Train Abuse on Twitter</b> available"
        },
        {
            "date": "Oct 25, 2020",
            "msg": "Our paper <b>Detection of Novel Social Bots by Ensembles of Specialized Classifiers</b> has been published in the Proceedings of CIKM 2020"
        },
        {
            "date": "Sep 2, 2020",
            "msg": "Botometer V4 and BotometerLite are now available through RapidAPI, check out the <a href='https://cnets.indiana.edu/blog/2020/09/01/botometer-v4/' target='_blank'>announcement</a> "
        },
        {
			"date": "Jul 18, 2020",
			"msg": "Our paper <b>Asymmetrical Perceptions of Partisan Political Bots</b> has been published by New Media & Society, the preprint version is also available"
		},
		{
			"date": "Jul 10, 2020",
			"msg": "Our paper <b>BiRank: Fast and Flexible Ranking on Bipartite Networks with R and Python</b> has been published by The Journal of Open Source Software, the package is available"
        }
    ],
    "project_highlights": [
        {
            "project_class": "1. Bad actors on social media",
            "projects": [
                {
                    "image": "botometer",
                    "title": "Social bot detection",
                    "msg": "Social bots are social media accounts controlled in part or completely by algorithms. They are involved in the online discussions around various critical issues like elections and public health, trying the manipulate the public opinion. To aid the daily usage for the public and studies on social media for researchers, I build tools to detect the social bots. <br> <a href='https://botometer.osome.iu.edu/' target='_blank'>Botometer</a> is a machine learning tool that extracts over 1000 different features from a Twitter account and evaluates its likelihood of being social bot. Botometer is handling over 450,000 requests every day and serves as the foundation for many studies. <br> <a href='https://botometer.osome.iu.edu/botometerlite' target='_blank'>BotometerLite</a> is a highly efficient bot detection tool that can process millions of accounts in minutes. With the novel evaluation system and model selection method, BotometerLite is able to achieve comparable accuracy with Botometer."
                },
                {
                    "image": "trainnet",
                    "title": "Political follow trains on Twitter",
                    "msg": "A growing body of evidence points to critical vulnerabilities of social media, such as the emergence of partisan echo chambers and the viral spread of misinformation. In our recent <a href='https://arxiv.org/abs/2010.13691' target='_blank'><i class='far fa-file-pdf'></i> paper</a>, we show that these vulnerabilities are amplified by abusive behaviors associated with so-called ''follow trains'' on Twitter, in which long lists of like-minded accounts are mentioned for others to follow. This leads to the formation of highly dense and hierarchical echo chambers. We present the first systematic analysis of U.S. political train networks, which involve many thousands of hyper-partisan accounts. These accounts engage in various suspicious behaviors, including some that violate platform policies: we find evidence of inauthentic automated accounts, artificial inflation of friends and followers, and abnormal content deletion. The networks are also responsible for amplifying toxic content from low-credibility and conspiratorial sources. Platforms may be reluctant to curb this kind of abuse for fear of being accused of political bias. As a result, the political echo chambers manufactured by follow trains grow denser and train accounts accumulate influence; even political leaders occasionally engage with them."
                },
                {
                    "image": "systembias",
                    "title": "Biases in Twitter data sampling",
                    "msg": "Researchers have used data from Twitter to analyze public opinions and forecast election results. Many recent studies, including some of our own, reveal the existence of inauthentic actors such as malicious social bots, suggesting that not every message is a genuine expression from a legitimate user. However, the prevalence of inauthentic activities in social data streams is still unclear, making it difficult to gauge biases of analyses based on such data. We attempt to close this gap in a recent <a href='https://arxiv.org/abs/2006.01447' target='_blank'><i class='far fa-file-pdf'></i> paper</a> using Twitter data from the 2018 U.S. midterm elections. We find that hyperactive accounts are over-represented in volume samples. In comparison with the self-identified voters, hyperactive accounts are more likely to exhibit various suspicious behaviors and share low-credibility information. "
                },
                {
                    "image": "botperception",
                    "title": "Human perceptions of political bots",
                    "msg": "Bots are prevalent in online political discussion. In our recent <a href='https://doi.org/10.1177/1461444820942744' target='_blank'><i class='far fa-file-pdf'></i> paper</a>, we examine the perceptions of bots with partisan personas by conducting an experiment with human subjects. Our analysis reveals asymmetrical partisan-motivated reasoning, in that conservative profiles appear to be more confusing and Republican participants perform less well in the recognition task. Moreover, Republican users are more likely to confuse conservative bots with humans, whereas Democratic users are more likely to confuse conservative human users with bots."
                },
                {
                    "image": "misinfocovid19",
                    "title": "Prevalence of low-credibility information about COVID-19",
                    "msg": "We estimate the prevalence of links to low-credibility information on Twitter during the novel coronavirus outbreak, and the role of bots in spreading these links in a recent <a href='https://doi.org/10.36190/2020.16' target='_blank'><i class='far fa-file-pdf'></i> paper</a>. We find that the combined volume of tweets linking to low-credibility information is comparable to the volume of New York Times articles and CDC links. The majority of this content spreads via retweets. Social bots are involved in both posting and amplifying low-credibility information, although the majority of volume is generated by likely humans."
                },
                {
                    "image": "botslayer",
                    "title": "Bot amplification detection & visualization",
                    "msg": "Inauthentic actors like social bots often act in coordination to increase influence and evade detection. We therefore also build tools that can detect and visualize such operations. <br> <a href='https://osome.iuni.iu.edu/tools/botslayer/' target='_blank'>BotSlayer</a> helps to track and detect potential coordinated manipulation on Twitter. It's free and easy to install, allowing everyone to own a customized instance running in the could. We also provide an open source version <a href='https://github.com/IUNetSci/BotSlayer-CE' target='_blank'>BotSlayer-CE</a>. <br> <a href='https://hoaxy.iuni.iu.edu/' target='_blank'> Hoaxy</a> visualizes the information spreading on Twitter. The close integration with Botometer and BotSlayer makes it a powerful yet handy tool for in-depth investigation of inauthentic behaviors."
                }
            ]
            
        },
        {
            "project_class": "2. Opioid epidemic in U.S.",
            "projects": [
                {
                    "image": "shopper",
                    "title": "Network prominence indicates drug seeking behavior",
                    "msg": "Traditional methods for identifying drug seeking patients rely on each individual's medical history. We find that it's beneficial to consider the provider-patient prescription networks, which account for the social processes among the actors. In our <a href='https://doi.org/10.1371/journal.pone.0223849' target='_blank'><i class='far fa-file-pdf'></i> paper</a>, we show that PageRank can be used to effectively identify these drug seekers. However, the naive PageRank algorithm requires one-mode projection on the bipartite network among the providers and patients, which may distort the network topology. In a recent <a href='https://doi.org/10.31235/osf.io/hazvs' target='_blank'><i class='far fa-file-pdf'></i> paper</a>, we further demonstrate that the bipartite PageRank algorithms that rank nodes directly on the bipartite networks can better predict high risk patients. <br> We implement the bipartite PageRank algorithms for the community. Our package is available both in Python (<a href='https://pypi.org/project/birankpy/' target='_blank'>birankpy</a>) and R (<a href='https://cran.r-project.org/web/packages/birankr/index.html' target='_blank'>birankr</a>). Source code and documentation can be found on <a href='https://github.com/BrianAronson/birankr'><i class='fab fa-github-square'></i> GitHub</a>."
                }
            ]
        },
        {
            "project_class": "3. Network science",
            "projects": [
                {
                    "image": "modelfree",
                    "title": "Model-free hidden geometry of complex networks",
                    "msg": "The fundamental idea of embedding a network in a metric space is rooted in the principle of proximity preservation. Nodes are mapped into points of the space with pairwise distance that reflects their proximity in the network. Popular methods employed in network embedding either rely on implicit approximations of the principle of proximity preservation or implement it by enforcing the geometry of the embedding space, thus hindering geometric properties that networks may spontaneously exhibit. In our <a href='https://arxiv.org/abs/2011.08103' target='_blank'><i class='far fa-file-pdf'></i> paper</a>, we take advantage of a model-free embedding method explicitly devised for preserving pairwise proximity, and characterize the geometry emerging from the mapping of several networks, both real and synthetic. We show that the learned embedding has simple and intuitive interpretations: the distance of a node from the geometric center is representative for its closeness centrality, and the relative positions of nodes reflect the community structure of the network. Proximity can be preserved in relatively low-dimensional embedding spaces and the hidden geometry displays optimal performance in guiding greedy navigation regardless of the specific network topology."
                },
                {
                    "image": "persona2vec",
                    "title": "Multi-role representations learning",
                    "msg": "Most network embedding algorithms assign a single vector to each node, implicitly assuming that a single representation is enough to capture all characteristics of the node. However, across many domains, it is common to observe pervasively overlapping community structure, where most nodes belong to multiple communities, playing different roles depending on the contexts. We propose persona2vec, a graph embedding framework that efficiently learns multiple representations of nodes based on their structural contexts. Checkout our <a href='https://arxiv.org/abs/2006.04941' target='_blank'><i class='far fa-file-pdf'></i> paper</a> and <a href='https://github.com/jisungyoon/persona2vec'><i class='fab fa-github-square'></i> GitHub</a>. "
                }
            ]
        }
    ]
}